# ğŸš€ SOLUÃ‡ÃƒO CLOUD RUN - ARQUIVOS 150MB+

## ğŸ¯ **Objetivo**
Upload de arquivos CSV de **150MB+** no Google Cloud Run, contornando o limite de **32MB**.

## âš¡ **MÃ©todo: Signed URLs do Google Cloud Storage**

### ğŸ”§ **Como Funciona:**
1. **UsuÃ¡rio solicita link**: Digite nome do arquivo â†’ Gerar Link
2. **Upload direto ao GCS**: Use curl/PowerShell para enviar arquivo
3. **Processamento automÃ¡tico**: AplicaÃ§Ã£o baixa do GCS e processa
4. **Limpeza automÃ¡tica**: Arquivo Ã© removido do GCS apÃ³s processamento

## ğŸ“‹ **Interface de Uso**

### **Passo 1: Gerar Link de Upload**
```
ğŸ“‚ Upload de Arquivo CSV (150MB+)
â˜ï¸ Google Cloud Run - Upload via Signed URL

Nome do arquivo CSV: [meus_dados.csv]
[ğŸ”— Gerar Link de Upload]
```

### **Passo 2: Upload via Terminal**
```bash
# Linux/Mac
curl -X PUT -H "Content-Type: text/csv" --data-binary @meus_dados.csv "SIGNED_URL"

# Windows PowerShell
Invoke-RestMethod -Uri "SIGNED_URL" -Method Put -InFile "meus_dados.csv" -ContentType "text/csv"
```

### **Passo 3: Processar Dados**
```
ğŸ“¥ Processar Arquivo Enviado
Nome do blob no GCS: [uploads/20250929_143022_meus_dados.csv]
[ğŸ“Š Carregar e Processar Dados]
```

## ğŸ”„ **Fluxo Completo**

```mermaid
graph LR
    A[Usuario] --> B[Gerar Signed URL]
    B --> C[Upload via curl/PowerShell]
    C --> D[GCS Storage]
    D --> E[Download & Processo]
    E --> F[DataFrame Pandas]
    F --> G[Delete GCS File]
```

## ğŸ› ï¸ **ConfiguraÃ§Ãµes TÃ©cnicas**

### **Limites Removidos:**
- âŒ st.file_uploader (causa erro 413)
- âŒ Upload direto via Streamlit
- âŒ Processamento local de arquivos grandes

### **ConfiguraÃ§Ãµes aplicadas:**
```toml
# .streamlit/config.toml
maxUploadSize = 1
maxMessageSize = 1
```

```dockerfile
# Dockerfile
--server.maxUploadSize=1 --server.maxMessageSize=1
```

## ğŸ“Š **Suporte a Diferentes CenÃ¡rios**

### **Arquivos Grandes (150MB+)**
- âœ… **Signed URLs**: MÃ©todo principal
- âœ… **URLs pÃºblicas**: Para arquivos jÃ¡ online
- âœ… **Timeout estendido**: 2 minutos para download

### **Arquivos MÃ©dios (30-150MB)**
- âœ… **Via URL**: Processamento automÃ¡tico via GCS
- âœ… **DetecÃ§Ã£o inteligente**: Auto-roteamento para GCS

### **URLs PÃºblicas**
- âœ… **Qualquer tamanho**: Suporte completo
- âœ… **ValidaÃ§Ã£o**: VerificaÃ§Ã£o de tipo CSV
- âœ… **Fallback**: Processamento direto se < 30MB

## ğŸš€ **Deploy**

```bash
.\deploy-cloudrun.bat groovy-rope-471520-c9
```

## ğŸ‰ **Vantagens**

1. **âœ… Sem LimitaÃ§Ãµes**: Arquivos atÃ© 200MB+ suportados
2. **âœ… Cloud Native**: Aproveitamento total do GCS
3. **âœ… Zero Erro 413**: Bypass completo dos limites do Cloud Run
4. **âœ… Interface Simples**: Processo claro em 3 passos
5. **âœ… Cleanup AutomÃ¡tico**: Gerenciamento de recursos otimizado
6. **âœ… MÃºltiplas OpÃ§Ãµes**: Signed URL + URLs pÃºblicas

## ğŸ“ **Exemplo de Uso**

```bash
# 1. Na aplicaÃ§Ã£o: Gerar link para "vendas_2024.csv"
# 2. Terminal: Upload do arquivo
curl -X PUT -H "Content-Type: text/csv" \
  --data-binary @vendas_2024.csv \
  "https://storage.googleapis.com/i2a2-eda-uploads/uploads/20250929_143022_vendas_2024.csv?..."

# 3. Na aplicaÃ§Ã£o: Processar "uploads/20250929_143022_vendas_2024.csv"
# 4. Resultado: DataFrame com milhÃµes de linhas carregado!
```

## ğŸ¯ **Status Final**
**ğŸŸ¢ OTIMIZADO PARA CLOUD RUN** - Suporte nativo a arquivos 150MB+ sem limitaÃ§Ãµes!