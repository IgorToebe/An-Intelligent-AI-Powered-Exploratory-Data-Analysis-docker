# ðŸ“ Upload de Arquivos Grandes com Google Cloud Storage

## ðŸŽ¯ Objetivo

Esta soluÃ§Ã£o permite o upload de arquivos CSV de atÃ© **200MB** contornando o limite de 32MB do Cloud Run atravÃ©s do Google Cloud Storage com signed URLs.

## ðŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit     â”‚    â”‚   Cloud Run     â”‚    â”‚ Google Cloud    â”‚
â”‚   Frontend      â”‚    â”‚   Backend       â”‚    â”‚    Storage      â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ 1. Solicita URL â”‚â”€â”€â”€â–¶â”‚ 2. Gera Signed  â”‚    â”‚                 â”‚
â”‚                 â”‚    â”‚    URL          â”‚    â”‚                 â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ 4. Upload       â”‚â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â–¶â”‚ 3. Recebe       â”‚
â”‚    Direto       â”‚    â”‚                 â”‚    â”‚    Arquivo      â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ 6. Solicita     â”‚â”€â”€â”€â–¶â”‚ 5. Baixa e      â”‚â—€â”€â”€â”€â”‚                 â”‚
â”‚    Processamentoâ”‚    â”‚    Processa     â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸ”§ Como Funciona

### 1. **SolicitaÃ§Ã£o de Upload**

- UsuÃ¡rio seleciona arquivo grande (>30MB)
- Frontend solicita signed URL ao backend

### 2. **GeraÃ§Ã£o de Signed URL**

- Backend cria URL temporÃ¡ria (30min)
- URL permite upload direto ao GCS

### 3. **Upload Direto**

- Arquivo Ã© enviado diretamente ao GCS
- NÃ£o passa pelo Cloud Run (bypass do limite)

### 4. **Processamento**

- Backend baixa arquivo do GCS
- Converte para DataFrame
- Remove arquivo temporÃ¡rio

## ðŸ“‹ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente

```bash
# No Cloud Run
GOOGLE_CLOUD_PROJECT=your-project-id
GCS_BUCKET_NAME=i2a2-eda-uploads

# No secrets.toml (desenvolvimento)
GOOGLE_CLOUD_PROJECT = "your-project-id"
GCS_BUCKET_NAME = "i2a2-eda-uploads"
```

### PermissÃµes NecessÃ¡rias

O Cloud Run precisa das seguintes roles:

- `Storage Object Admin` - Para criar/ler/deletar objetos
- `Storage Admin` - Para gerenciar signed URLs

## ðŸ› ï¸ Setup do Bucket

### AutomÃ¡tico

```bash
# Windows
setup-gcs.bat your-project-id

# Linux/Mac
./setup-gcs.sh your-project-id
```

### Manual

```bash
# 1. Criar bucket
gsutil mb -p your-project-id -l us-central1 gs://i2a2-eda-uploads

# 2. Configurar CORS
cat > cors.json << EOF
[{
    "origin": ["https://*.streamlit.app", "https://*.run.app", "http://localhost:*"],
    "method": ["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    "responseHeader": ["Content-Type", "Access-Control-Allow-Origin"],
    "maxAgeSeconds": 3600
}]
EOF

gsutil cors set cors.json gs://i2a2-eda-uploads

# 3. Configurar limpeza automÃ¡tica (opcional)
cat > lifecycle.json << EOF
{
    "rule": [{
        "action": {"type": "Delete"},
        "condition": {
            "age": 1,
            "matchesPrefix": ["uploads/"]
        }
    }]
}
EOF

gsutil lifecycle set lifecycle.json gs://i2a2-eda-uploads
```

## ðŸ”’ SeguranÃ§a

### Signed URLs

- âœ… Tempo limitado (30 minutos)
- âœ… Acesso especÃ­fico (PUT apenas)
- âœ… Tamanho limitado (200MB max)
- âœ… Tipo MIME validado

### CORS

- âœ… DomÃ­nios permitidos especÃ­ficos
- âœ… MÃ©todos limitados
- âœ… Headers controlados

### Limpeza AutomÃ¡tica

- âœ… Arquivos removidos apÃ³s 1 dia
- âœ… Apenas pasta "uploads/"
- âœ… NÃ£o afeta outros arquivos

## ðŸ’° Custos

### Google Cloud Storage

- **Armazenamento**: $0.020 por GB/mÃªs (Standard)
- **OperaÃ§Ãµes**: $0.005 por 1K operaÃ§Ãµes
- **Rede**: GrÃ¡tis para mesmo projeto

### Estimativa Mensal

```
100 uploads de 150MB/dia:
- Armazenamento: ~$0.10 (temporÃ¡rio)
- OperaÃ§Ãµes: ~$0.15
- Total: ~$0.25/mÃªs
```

## ðŸ“Š Limites

| Recurso             | Limite     |
| ------------------- | ---------- |
| Tamanho mÃ¡ximo      | 200MB      |
| Tempo de upload     | 5 minutos  |
| Signed URL validade | 30 minutos |
| RetenÃ§Ã£o temporÃ¡ria | 1 dia      |
| Uploads simultÃ¢neos | 10         |

## ðŸ” Monitoramento

### Logs Ãšteis

```bash
# Logs do Cloud Run
gcloud logging read "resource.type=cloud_run_revision" --limit=50

# Logs do Cloud Storage
gcloud logging read "resource.type=gcs_bucket" --limit=50

# MÃ©tricas de upload
gcloud logging read "jsonPayload.message=~'Upload.*GCS'" --limit=20
```

### MÃ©tricas no Console

- **Cloud Run**: Requests, latÃªncia, erros
- **Cloud Storage**: OperaÃ§Ãµes, bandwidth, armazenamento
- **Cloud Monitoring**: Dashboards customizados

## ðŸš¨ Troubleshooting

### Problemas Comuns

#### 1. Erro 403 - PermissÃµes

```bash
# Verificar IAM
gcloud projects get-iam-policy your-project-id

# Adicionar permissÃ£o
gcloud projects add-iam-policy-binding your-project-id \
    --member="serviceAccount:SERVICE_ACCOUNT" \
    --role="roles/storage.objectAdmin"
```

#### 2. CORS Error

```bash
# Verificar CORS
gsutil cors get gs://i2a2-eda-uploads

# Reconfigurar
gsutil cors set cors.json gs://i2a2-eda-uploads
```

#### 3. Upload Timeout

- Verificar tamanho do arquivo
- Verificar conexÃ£o de rede
- Aumentar timeout no cÃ³digo

#### 4. Signed URL Expirada

- URLs vÃ¡lidas por apenas 30 minutos
- Regenerar se necessÃ¡rio
- Verificar fuso horÃ¡rio do servidor

## ðŸ”„ Fallback Strategy

Se GCS nÃ£o estiver disponÃ­vel:

1. **Fallback automÃ¡tico** para upload tradicional
2. **Limite de 30MB** aplicado
3. **Aviso ao usuÃ¡rio** sobre limitaÃ§Ã£o
4. **Funcionalidade mantida** para arquivos pequenos

## ðŸ“ˆ OtimizaÃ§Ãµes Futuras

### PossÃ­veis Melhorias

- **Upload resumable** para arquivos muito grandes
- **CompressÃ£o automÃ¡tica** antes do upload
- **Streaming processing** para economizar memÃ³ria
- **Cache inteligente** para arquivos frequentes
- **Multi-part upload** para paralelizaÃ§Ã£o

### Alternativas

- **Firebase Storage** - Mais simples para MVPs
- **AWS S3** - Se jÃ¡ usando AWS
- **Azure Blob** - Se jÃ¡ usando Azure
- **Chunked upload** - Dividir arquivo em partes
